{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3e7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "ffmpeg_bin_path = r\"C:\\Users\\arezk\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-8.0.1-full_build\\bin\"\n",
    "os.environ[\"PATH\"] += os.pathsep + ffmpeg_bin_path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85364091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import musdb\n",
    "import museval\n",
    "import os\n",
    "from glob import glob\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "from src.utils import separate_vocals\n",
    "from src.model import Unet\n",
    "from scipy.io import wavfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d95477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../checkpoints/musdb18_V2/model_last.pth\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "test_data_path = '../data/musdb18/'\n",
    "output_folder = '../outputs/'\n",
    "\n",
    "# Load the model\n",
    "model = Unet()\n",
    "model_path = '../checkpoints/musdb18_V2/model_last.pth'\n",
    "model.load(model_path)\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf4808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 test tracks to process\n"
     ]
    }
   ],
   "source": [
    "# Load MUSDB18 test set\n",
    "mus_test = musdb.DB(root=test_data_path, is_wav=False, subsets='test')\n",
    "print(f\"Found {len(mus_test.tracks)} test tracks to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcdbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tracks: 100%|██████████| 50/50 [10:53<00:00, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ All 50 tracks processed and saved to ../outputs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each track\n",
    "for i, track in enumerate(tqdm(mus_test.tracks, desc=\"Processing tracks\")):\n",
    "    track_name = track.name.replace(' ', '_').replace('/', '_')\n",
    "    output_path = os.path.join(output_folder, f'{track_name}_vocal.wav')\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if os.path.exists(output_path):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Get audio from track\n",
    "    audio = track.audio  # (n_samples, 2) stereo\n",
    "    sr = track.rate      # Usually 44100\n",
    "    \n",
    "    \n",
    "    # Separate vocals\n",
    "    vocal_audio_predicted = separate_vocals(model, audio, sr=sr)\n",
    "    \n",
    "    \n",
    "    # Save audio\n",
    "    sf.write(output_path, vocal_audio_predicted, sr)\n",
    "    \n",
    "    del vocal_audio_predicted\n",
    "\n",
    "print(f\"\\ All {len(mus_test.tracks)} tracks processed and saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ba36a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/Zeno_-_Signs_vocal.wav\n"
     ]
    }
   ],
   "source": [
    "# display an example \n",
    "print(output_path)\n",
    "# display(ipd.Audio(output_path, rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3941be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SDR: -87.61 dB\n",
      "  SIR: 11.86 dB\n",
      "  SAR: 1.14 dB\n",
      "\n",
      "  SDR: -87.90 dB\n",
      "  SIR: 14.47 dB\n",
      "  SAR: 0.26 dB\n",
      "\n",
      "  SDR: -88.81 dB\n",
      "  SIR: 14.24 dB\n",
      "  SAR: 2.41 dB\n",
      "\n",
      "  SDR: -88.54 dB\n",
      "  SIR: 4.91 dB\n",
      "  SAR: 2.13 dB\n",
      "\n",
      "  SDR: -80.76 dB\n",
      "  SIR: -6.88 dB\n",
      "  SAR: -0.55 dB\n",
      "\n",
      "  SDR: -89.34 dB\n",
      "  SIR: 16.01 dB\n",
      "  SAR: 1.63 dB\n",
      "\n",
      "  SDR: -83.06 dB\n",
      "  SIR: 15.58 dB\n",
      "  SAR: 0.44 dB\n",
      "\n",
      "  SDR: -89.17 dB\n",
      "  SIR: 11.19 dB\n",
      "  SAR: 1.87 dB\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 44\u001b[0m\n\u001b[0;32m     38\u001b[0m estimates \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocals\u001b[39m\u001b[38;5;124m'\u001b[39m: vocal_estimate,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccompaniment\u001b[39m\u001b[38;5;124m'\u001b[39m: accompaniment_estimate\n\u001b[0;32m     41\u001b[0m }\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Evaluate using museval\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmuseval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_mus_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./eval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m all_scores\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Print results for this track\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arezk\\Desktop\\M2\\this year\\son\\TP\\TP4\\Unet_tp_son\\lib\\site-packages\\museval\\__init__.py:233\u001b[0m, in \u001b[0;36meval_mus_track\u001b[1;34m(track, user_estimates, output_dir, mode, win, hop)\u001b[0m\n\u001b[0;32m    230\u001b[0m     audio_estimates\u001b[38;5;241m.\u001b[39mappend(user_estimates[target])\n\u001b[0;32m    231\u001b[0m     audio_reference\u001b[38;5;241m.\u001b[39mappend(track\u001b[38;5;241m.\u001b[39mtargets[target]\u001b[38;5;241m.\u001b[39maudio)\n\u001b[1;32m--> 233\u001b[0m SDR, ISR, SIR, SAR \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_reference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_estimates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# iterate over all targets\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(eval_targets):\n",
      "File \u001b[1;32mc:\\Users\\arezk\\Desktop\\M2\\this year\\son\\TP\\TP4\\Unet_tp_son\\lib\\site-packages\\museval\\__init__.py:340\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(references, estimates, win, hop, mode, padding)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding:\n\u001b[0;32m    338\u001b[0m     references, estimates \u001b[38;5;241m=\u001b[39m pad_or_truncate(references, estimates)\n\u001b[1;32m--> 340\u001b[0m SDR, ISR, SIR, SAR, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbss_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_permutation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframewise_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbsseval_sources_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SDR, ISR, SIR, SAR\n",
      "File \u001b[1;32mc:\\Users\\arezk\\Desktop\\M2\\this year\\son\\TP\\TP4\\Unet_tp_son\\lib\\site-packages\\museval\\metrics.py:289\u001b[0m, in \u001b[0;36mbss_eval\u001b[1;34m(reference_sources, estimated_sources, window, hop, compute_permutation, filters_len, framewise_filters, bsseval_sources_version)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Cj\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m framewise_filters:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# compute filters on whole signals if no framewise filters\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     (G, sf, C) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_GsfC\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     Cj \u001b[38;5;241m=\u001b[39m compute_Cj()\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m# loop over all windows\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arezk\\Desktop\\M2\\this year\\son\\TP\\TP4\\Unet_tp_son\\lib\\site-packages\\museval\\metrics.py:274\u001b[0m, in \u001b[0;36mbss_eval.<locals>.compute_GsfC\u001b[1;34m(win)\u001b[0m\n\u001b[0;32m    272\u001b[0m C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((nsrc, nsrc, nchan, filters_len, nchan))\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m jtrue \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nsrc):\n\u001b[1;32m--> 274\u001b[0m     C[jtrue] \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_projection_filters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimated_sources\u001b[49m\u001b[43m[\u001b[49m\u001b[43mjtrue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (G, sf, C)\n",
      "File \u001b[1;32mc:\\Users\\arezk\\Desktop\\M2\\this year\\son\\TP\\TP4\\Unet_tp_son\\lib\\site-packages\\museval\\metrics.py:576\u001b[0m, in \u001b[0;36m_compute_projection_filters\u001b[1;34m(G, sf, estimated_source)\u001b[0m\n\u001b[0;32m    573\u001b[0m filters_len \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# zero pad estimates and put chan in first dimension\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m estimated_source \u001b[38;5;241m=\u001b[39m \u001b[43m_zeropad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimated_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# compute its FFT\u001b[39;00m\n\u001b[0;32m    579\u001b[0m n_fft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mceil(np\u001b[38;5;241m.\u001b[39mlog2(nsampl \u001b[38;5;241m+\u001b[39m filters_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\arezk\\Desktop\\M2\\this year\\son\\TP\\TP4\\Unet_tp_son\\lib\\site-packages\\museval\\metrics.py:510\u001b[0m, in \u001b[0;36m_zeropad\u001b[1;34m(sig, N, axis)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# zero pad\u001b[39;00m\n\u001b[0;32m    509\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((sig\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m N,) \u001b[38;5;241m+\u001b[39m sig\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m--> 510\u001b[0m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m sig\n\u001b[0;32m    511\u001b[0m \u001b[38;5;66;03m# put back axis in place\u001b[39;00m\n\u001b[0;32m    512\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(out, \u001b[38;5;241m0\u001b[39m, axis)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load MUSDB18 test set\n",
    "mus_test = musdb.DB(root='../data/musdb18', is_wav=False, subsets='test')\n",
    "separated_vocals_folder = '../outputs/'\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "# Loop through all test tracks\n",
    "for i, track in enumerate(mus_test.tracks):\n",
    "    track_name = track.name.replace(' ', '_').replace('/', '_')\n",
    "    \n",
    "        \n",
    "    # Load separated vocal\n",
    "    vocal_file = os.path.join(separated_vocals_folder, f'{track_name}_vocal.wav')\n",
    "    \n",
    "    if not os.path.exists(vocal_file):\n",
    "        print(f\"   Warning: File not found - {vocal_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Load separated vocal\n",
    "    sr, vocal_estimate = wavfile.read(vocal_file)\n",
    "    mixture_shape = track.audio.shape\n",
    "    \n",
    " \n",
    "    \n",
    "    # Make stereo if mono\n",
    "    if vocal_estimate.ndim == 1:\n",
    "        vocal_estimate = np.stack([vocal_estimate, vocal_estimate], axis=1)\n",
    "    \n",
    "    \n",
    "    # Pad if necessary\n",
    "    if len(vocal_estimate) < len(track.audio):\n",
    "        padding = len(track.audio) - len(vocal_estimate)\n",
    "        vocal_estimate = np.pad(vocal_estimate, ((0, padding), (0, 0)), mode='constant')\n",
    "    \n",
    "    accompaniment_estimate = track.audio - vocal_estimate\n",
    "    \n",
    "    # Prepare estimates dict\n",
    "    estimates = {\n",
    "        'vocals': vocal_estimate,\n",
    "        'accompaniment': accompaniment_estimate\n",
    "    }\n",
    "    \n",
    "    # Evaluate using museval\n",
    "    scores = museval.eval_mus_track(track, estimates, output_dir='../eval')\n",
    "\n",
    "    all_scores.append(scores)\n",
    "    \n",
    "\n",
    "\n",
    "    # Print results for this track\n",
    "\n",
    "    vocals_scores = scores.df[scores.df['target'] == 'vocals']\n",
    "\n",
    "    median_sdr = vocals_scores[vocals_scores['metric'] == 'SDR']['score'].median()\n",
    "    median_sir = vocals_scores[vocals_scores['metric'] == 'SIR']['score'].median()\n",
    "    median_sar = vocals_scores[vocals_scores['metric'] == 'SAR']['score'].median()\n",
    "\n",
    "    print(f\"  SDR: {median_sdr:.2f} dB\")\n",
    "    print(f\"  SIR: {median_sir:.2f} dB\")\n",
    "    print(f\"  SAR: {median_sar:.2f} dB\")\n",
    "\n",
    "    if i == 6 : \n",
    "        break; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09d4c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE RESULTS\n",
      "Average SDR: -86.90 ± 2.99 dB\n",
      "Average SIR: 10.17 ± 7.25 dB\n",
      "Average SAR: 1.17 ± 0.97 dB\n"
     ]
    }
   ],
   "source": [
    "# Calculate average scores\n",
    "all_sdr = []\n",
    "all_sir = []\n",
    "all_sar = []\n",
    "\n",
    "for score in all_scores:\n",
    "    vocals_df = score.df[score.df['target'] == 'vocals']\n",
    "    all_sdr.append(vocals_df[vocals_df['metric'] == 'SDR']['score'].median())\n",
    "    all_sir.append(vocals_df[vocals_df['metric'] == 'SIR']['score'].median())\n",
    "    all_sar.append(vocals_df[vocals_df['metric'] == 'SAR']['score'].median())\n",
    "\n",
    "print(\"AVERAGE RESULTS\")\n",
    "print(f\"Average SDR: {np.mean(all_sdr):.2f} ± {np.std(all_sdr):.2f} dB\")\n",
    "print(f\"Average SIR: {np.mean(all_sir):.2f} ± {np.std(all_sir):.2f} dB\")\n",
    "print(f\"Average SAR: {np.mean(all_sar):.2f} ± {np.std(all_sar):.2f} dB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Unet_tp_son",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
